{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varsh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import math\n",
    "import os\n",
    "import gradio as gr\n",
    "def process_video(input_video):\n",
    "    # Load video file\n",
    "    cap = cv2.VideoCapture(input_video.name)\n",
    "    # Check if the video opened successfully\n",
    "    if not cap.isOpened():\n",
    "        return \"Error: Couldn't open video file.\", None\n",
    "    # Get video properties for saving\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    # Create the output directory if it doesn't exist\n",
    "    output_dir = \"output\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    # Define the codec and create VideoWriter object\n",
    "    output_video_path = os.path.join(output_dir, \"processed_video.avi\")\n",
    "    output_video = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*\"XVID\"), fps, (frame_width, frame_height))\n",
    "    # Check if VideoWriter was successfully initialized\n",
    "    if not output_video.isOpened():\n",
    "        return \"Error: Couldn't open the video writer.\", None\n",
    "    # Initialize variables\n",
    "    count = 0\n",
    "    center_points_prev_frame = []\n",
    "    tracking_objects = {}\n",
    "    track_id = 0\n",
    "    # Create a background subtractor (using MOG2 in this case)\n",
    "    fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "    # Initialize the minimum bounding box size for car detection (tune this based on your use case)\n",
    "    min_car_area = 500  # Minimum area of bounding box to track (adjust as necessary)\n",
    "    max_car_area = 5000  # Maximum area of bounding box (adjust as necessary)\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        # Apply background subtraction\n",
    "        fg_mask = fgbg.apply(frame)\n",
    "        # Find contours in the mask (i.e., detected moving objects)\n",
    "        contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        center_points_cur_frame = []\n",
    "        for contour in contours:\n",
    "            # Filter out small or too large contours (noise and irrelevant objects)\n",
    "            if cv2.contourArea(contour) < min_car_area or cv2.contourArea(contour) > max_car_area:\n",
    "                continue\n",
    "            # Get the bounding box around each contour\n",
    "            (x, y, w, h) = cv2.boundingRect(contour)\n",
    "            # Calculate the center points of the bounding box\n",
    "            cx = int((x + x + w) / 2)\n",
    "            cy = int((y + y + h) / 2)\n",
    "            center_points_cur_frame.append((cx, cy))\n",
    "            # Draw rectangle around the object\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        # Update tracking objects only if cars are detected consistently\n",
    "        for pt in center_points_cur_frame:\n",
    "            same_object_detected = False\n",
    "            for object_id, prev_pt in tracking_objects.items():\n",
    "                distance = math.hypot(prev_pt[0] - pt[0], prev_pt[1] - pt[1])\n",
    "                # Only update if the object is sufficiently close (distance threshold)\n",
    "                if distance < 50:  # Threshold distance for matching objects (adjust as needed)\n",
    "                    tracking_objects[object_id] = pt\n",
    "                    same_object_detected = True\n",
    "                    break\n",
    "            # Assign a new ID to a new object (if no match found)\n",
    "            if not same_object_detected:\n",
    "                tracking_objects[track_id] = pt\n",
    "                track_id += 1\n",
    "        # Draw tracking points and IDs\n",
    "        for object_id, pt in tracking_objects.items():\n",
    "            # Draw a filled circle for tracking\n",
    "            cv2.circle(frame, pt, 5, (0, 0, 255), -1)\n",
    "            # Ensure IDs are drawn on top of the frame\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                str(object_id),\n",
    "                (pt[0] - 10, pt[1] - 10),  # Offset for better visibility\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.6,\n",
    "                (255, 255, 255),  # White text for visibility\n",
    "                2,\n",
    "                lineType=cv2.LINE_AA,  # Anti-aliased text\n",
    "            )\n",
    "        # Write the processed frame to the output video\n",
    "        output_video.write(frame)\n",
    "    # Release everything when done\n",
    "    cap.release()\n",
    "    output_video.release()\n",
    "    return \"Processing complete. The output video is saved.\", output_video_path\n",
    "# Create Gradio interface\n",
    "gr.Interface(\n",
    "    fn=process_video,\n",
    "    inputs=gr.File(label=\"Upload Video\"),\n",
    "    outputs=[gr.Textbox(label=\"Status\"), gr.File(label=\"Processed Video\")],\n",
    "    title=\"Object Tracking in Video\",\n",
    "    description=\"Upload a video to track cars and generate a processed output video.\",\n",
    ").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
